---

- name: Build application artifacts
  hosts: all
  connection: local
  gather_facts: False
  vars:
    state: "present"
  tasks:
    - name: Manage IAM Role and Profile
      ec2_iam_role:
        profile: "{{ profile }}"
        state: "{{ state }}"
        instance_profile_name: "{{ instance_profile_name }}"
        role_name: "{{ role_name }}"
        policies: "{{ role_policies }}"
      tags:
      - iam

    - name: Manage ELB security group
      ec2_group_local:
        profile: "{{ profile }}"
        description: "{{ elb_security_group.description }}"
        name: "{{ elb_security_group.name }}"
        vpc_id: "{{ vpc_id }}"
        region: "{{ aws_region }}"
        rules: "{{ elb_security_group.rules }}"
        tags: "{{ elb_security_group.tags }}"
      register: elb_sec_group
      when: elbs is defined
      tags:
        - elb

    - name: Set Base Security Rules
      set_fact: 
        service_security_group_rules: "{{ service_security_group.rules }}"
      when: service_port is not defined

    - name: Merge Base and Service Port Security Rules
      set_fact: 
        service_security_group_rules: "{{ service_security_group.rules + service_port_rules }}"
      when: service_port is defined

    - name: Manage service security group
      ec2_group_local:
        profile: "{{ profile }}"
        description: "{{ service_security_group.description }}"
        name: "{{ service_security_group.name }}"
        vpc_id: "{{ vpc_id }}"
        region: "{{ aws_region }}"
        rules: "{{ service_security_group_rules }}"
        tags: "{{ service_security_group.tags }}"
      register: service_sec_group

    - name: Set public Base ACLs
      set_fact: 
        service_public_acl_rules: "{{ public_acls.rules }}"
      when: service_port is not defined

    - name: Merge public Base and Service Port ACLs
      set_fact: 
        service_public_acl_rules: "{{ public_acls.rules + service_port_public_acls }}"
      when: service_port is defined

    - name: Manage Public ACLs
      ec2_acl:
        profile: "{{ profile }}"
        name: "{{ public_acls.name }}"
        vpc_id: "{{ vpc_id }}"
        state: "{{ state }}"
        region: "{{ aws_region }}"
        rules: "{{ service_public_acl_rules }}"
      register: created_public_acls

    - name: Set private Base ACLs
      set_fact: 
        service_private_acl_rules: "{{ private_acls.rules }}"
      when: service_port is not defined

    - name: Merge private Base and Service Port ACLs
      set_fact: 
        service_private_acl_rules: "{{ private_acls.rules + service_port_private_acls }}"
      when: service_port is defined

    - name: Manage Private ACLs
      ec2_acl:
        profile: "{{ profile }}"
        name: "{{ private_acls.name }}"
        vpc_id: "{{ vpc_id }}"
        state: "{{ state }}"
        region: "{{ aws_region }}"
        rules: "{{ service_private_acl_rules }}"
      register: created_private_acls

    - name: Merge created ACLs
      set_fact: 
        created_acls: "{{ created_public_acls.results | default([]) + created_private_acls.results | default([]) }}"

    - name: Apply function to acl_data
      util_map:
        function: 'zip_to_dict'
        input: "{{ created_acls }}"
        args:
          - "name"
          - "id"
      register: acl_data
         
    - name: Manage Service Subnets
      ec2_subnet:
        profile: "{{ profile }}"
        state: "{{ state }}"
        region: "{{ aws_region }}"
        name: "{{ item.name }}"
        vpc_id: "{{ vpc_id }}"
        cidr_block: "{{ item.cidr }}"
        az: "{{ item.az }}"
        route_table_id: "{{ item.route_table_id }}"
        tags: "{{ item.tags }}"
      register: created_service_subnets
      with_items: service_subnets

    #
    # Stubbed out
    # For now we'll be using an existing route table
    #
    # - name: Manage Route Table
    #   ec2_rt:
    #     state: "{{ state }}"
    #     region: "{{ aws_region }}"
    #     name: "{{ rt.name }}"
    #     vpc_id: "{{ vpc_id }}"
    #     destination_cidr: "{{ rt.destination_cidr }}"
    #     target: "local" # simplifying generalization of instnace-id, gateway-id or local
    #
    - name: Manage Private ELB Subnets
      ec2_subnet:
        profile: "{{ profile }}"
        state: "{{ state }}"
        region: "{{ aws_region }}"
        name: "{{ item.name }}"
        vpc_id: "{{ vpc_id }}"
        cidr_block: "{{ item.cidr }}"
        az: "{{ item.az }}"
        route_table_id: "{{ item.route_table_id }}"
        tags: "{{ item.tags }}"
      register: created_elb_private_subnets
      with_items: elb_private_subnets
      when: private_elb_subnet_1 is defined and private_elb_subnet_2 is defined
      tags:
        - elb

    - name: Check that internal ELBs have subnets
      fail: msg="If you set an elb scheme to 'internal' you must also define private_elb_subnet_1 and private_elb_subnet_2"
      when: private_elb_subnet_1 is not defined and private_elb_subnet_2 is not defined and elbs is defined and 'internal' in elbs|map(attribute='scheme')|list

    - name: Manage ELB
      ec2_elb_lb:
        profile: "{{ profile }}"
        region: "{{ aws_region }}"
        scheme: "{{ item.scheme }}"
        name: "{{ item.name}}"
        state: "{{ state }}"
        security_group_ids: "{{ elb_sec_group.group_id }}"
        subnets: "{{ created_elb_private_subnets.results|map(attribute='subnet_id')| list if ( item.scheme == 'internal' ) else elb_subnets}}"
        health_check: "{{ elb_healthcheck }}"
        listeners: "{{ elb_listeners }}"
        cross_az_load_balancing: "{{ elb_enable_cross_zone_loadbalancing }}"
        connection_draining_timeout: "{{ elb_draining_timeout }}"
      register: created_elbs
      with_items: elbs
      when: elbs is defined
      tags:
        - elb

    - name: Setup ELB DNS
      route53:
        command: "create"
        zone: "{{ dns_zone_name }}"
        record: "{{ item.elb.name }}.{{ dns_zone_name }}"
        type: "A"
        value: "{{ item.elb.dns_name }}"
        alias: true
        alias_hosted_zone_id: "{{ item.elb.hosted_zone_id }}"
        overwrite: true
      with_items: created_elbs.results
      when: elbs is defined
      tags:
        - elb

#
# Service related components
#
    - name: Manage the launch configuration
      ec2_lc:
        profile: "{{ profile }}"
        region: "{{ aws_region }}"
        name: "{{ service_config.name }}"
        image_id: "{{ service_config.ami }}"
        key_name: "{{ service_config.key_name }}"
        security_groups: "{{ service_sec_group.group_id }}"
        instance_type: "{{ service_config.instance_type }}"
        instance_profile_name: "{{ instance_profile_name }}"
        volumes: "{{ service_config.volumes }}"
        instance_monitoring: "{{ service_config.detailed_monitoring }}"
      when: auto_scaling_service

      #
      # Hack alert, this registers a string in the global namespace
      # of just the subnet ids for the service that were created above
      #
    - debug: msg="{{ created_service_subnets.results|map(attribute='subnet_id')| list | join(',') }}"
      register: service_vpc_zone_identifier_string

    - name: Transform tags into list dict format for the modules that expect it
      util_map:
        function: zip_to_listdict
        input: "{{ asg_instance_tags }}"
        args: ['key', 'value']
      register: listdict_asg_instance_tags

    - debug: msg="Instance Tags:{{ listdict_asg_instance_tags }}"

    - name: Manage ASG
      ec2_asg:
        profile: "{{ profile }}"
        region: "{{ aws_region }}"
        name: "{{ asg_name }}"
        launch_config_name: "{{ service_config.name }}"
        availability_zones: "{{ aws_availability_zones }}"
        min_size: "{{ asg_min_size }}"
        max_size: "{{ asg_max_size }}"
        desired_capacity: "{{ asg_desired_capacity }}"
        vpc_zone_identifier: "{{ service_vpc_zone_identifier_string.msg }}"
        tags: "{{ listdict_asg_instance_tags.function_output }}"
        load_balancers: "{% if elb is defined %}{{ created_elbs.results|map(attribute='elb.name')|list }}{% else %}[]{% endif %}"
      register: asg
      when: auto_scaling_service

    - name: Manage scaling policies
      ec2_scaling_policy:
        state: "{{ item.state }}"
        profile: "{{ item.profile }}"
        region: "{{ item.region }}"
        name: "{{ item.name }}"
        adjustment_type: "{{ item.adjustment_type }}"
        asg_name: "{{ item.asg_name }}"
        scaling_adjustment: "{{ item.scaling_adjustment }}"
        min_adjustment_step: "{{ item.min_adjustment_step }}"
        cooldown: "{{ item.cooldown }}"
      with_items: scaling_policies
      register: created_policies
      when: auto_scaling_service

    - name: Apply function to policy data
      util_map:
        function: 'zip_to_dict'
        input: "{{ created_policies.results }}"
        args:
          - "name"
          - "arn"
      register: policy_data
      when: auto_scaling_service

    - name: Manage metric alarms
      ec2_metric_alarm:
        profile: "{{ profile }}"
        state: "{{ item.state }}"
        region: "{{ aws_region }}"
        name: "{{ item.name }}"
        metric: "{{ item.metric }}"
        namespace: "{{ item.namespace }}"
        statistic: "{{ item.statistic }}"
        comparison: "{{ item.comparison }}"
        threshold: "{{ item.threshold }}"
        period: "{{ item.period }}"
        evaluation_periods: "{{ item.evaluation_periods }}"
        unit: "{{ item.unit }}"
        description: "{{ item.description }}"
        dimensions: "{{ item.dimensions }}"
        alarm_actions: "{{ policy_data.function_output[item.target_policy] }}"
      with_items: metric_alarms 
      when: auto_scaling_service

    - name: Transform tags into dict format for the modules that expect it
      util_map:
        function: zip_to_dict
        input: "{{ asg_instance_tags }}"
        args: ['key', 'value']
      register: reformatted_asg_instance_tags

    - name: See if instances already exist
      ec2_lookup:
        region: "{{ aws_region }}"
        tags: "{{ reformatted_asg_instance_tags.function_output }}"
      register: potential_existing_instances

    - name: Compare requested instances vs. current instances
      when: not auto_scaling_service and (potential_existing_instances.instances|length > create_instances | int)
      fail: msg="This playbook will not shrink the number of instances. {{create_instances }} requested. There are currently {{ potential_existing_instances.instances|length }} instances that match this tag." 

    #This task will create the number of instances requested (create_instances parameter). 
    # By default, it will create instances equaling the number of subnets specified.
    #Modulo logic explained: The subnet specified will be the instance number modulo the number of subnets, 
    # so that instances are balanced across subnets.
    - name: Manage instances
      ec2:
        profile: "{{ profile }}"
        region: "{{ aws_region }}"
        wait: "yes"
        group_id:
          - "{{ service_sec_group.group_id }}"
        key_name: "{{ service_config.key_name }}"
        vpc_subnet_id: "{{ created_service_subnets.results[item | int % created_service_subnets.results | length].subnet_id }}"
        instance_type: "{{ service_config.instance_type }}"
        instance_tags: "{{ reformatted_asg_instance_tags.function_output }}"
        image: "{{ service_config.ami }}"
        instance_profile_name: "{{ instance_profile_name }}"
        volumes: "{{ service_config.volumes }}"
        ebs_optimized: "{{ service_config.ebs_optimized }}"
        monitoring: "{{ detailed_monitoring }}"
      with_sequence: count={% if not auto_scaling_service %}{{ (create_instances | int - potential_existing_instances.instances|length) | default(created_service_subnets.results | length) }}{% else %}0{% endif %}
      when: not auto_scaling_service and (potential_existing_instances.instances|length < create_instances | int)
      register: created_instances


    - name: Add new instances to host group
      add_host:
        hostname: "{{ item.1.private_ip }}"
        instance_id: "{{ item.1.id }}"
        groups: created_instances_group
        #might need ansible_ssh_private_key_file and/or ansible_ssh_user
        ansible_ssh_user: ubuntu
        volumes: "{{ service_config.volumes }}"
      with_subelements:
        - created_instances.results | default({})
        - instances


- name: Configure launched instances
  hosts: created_instances_group
  gather_facts: False
  become: True
  tasks:
    #Wait in this play so it can multiplex across all launched hosts
    - name: Wait for hosts to be ready
      become: False
      local_action:
        module: wait_for
        host: "{{ inventory_hostname }}"
        port: 22

    #Must wait for the instance to be ready before gathering facts
    - name: Gather facts
      setup:

    - name: Unmount all specified disks that are currently mounted
      mount:
        name: "{{ item[0].mount }}"
        src: "{{ item[0].device }}"
        fstype: "{{ item[0].fstype }}"
        state: absent
      when: item[1].device_name == item[0].device
      with_nested:
        - ansible_mounts
        - volumes

    #Must use force=yes because AWS gives some ephemeral disks the wrong fstype and mounts them by default.
    #Since we don't do this task if any prior instances were found in the ec2_lookup task, it's safe to force.
    - name: Create filesystems
      filesystem:
        dev: "{{ item.device_name }}"
        fstype: ext4
        force: yes
      with_items: volumes

    - name: Mount disks
      mount:
        fstype: ext4
        name: "{{ item.mount }}"
        src: "{{ item.device_name }}"
        state: mounted
        fstype: "{{ item.fstype | default('ext4') }}"
        opts: "{{ item.options | default('defaults') }}"
      with_items: volumes


#Currently only supported in non-asg mode, when auto_scaling_service==false
#<http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html#enable-enhanced-networking>
#Done with local actions to avoid blocking on iteration
- name: Enable enhanced networking
  hosts: created_instances_group
  gather_facts: False
  tasks:
    - name: Shut down instances
      local_action:
        module: ec2
        instance_ids: "{{ instance_id }}"
        state: stopped
        region: "{{ aws_region }}"
        wait: yes
      when: enhanced_networking == true

    - name: Set enhanced networking instance attribute
      local_action:
        module: shell aws --profile {{ profile }} ec2 modify-instance-attribute --instance-id {{ instance_id }} --sriov-net-support simple
      when: enhanced_networking == true

    - name: Start instances
      local_action:
        module: ec2
        instance_ids: "{{ instance_id }}"
        state: running
        region: "{{ aws_region }}"
        wait: yes
      when: enhanced_networking == true
